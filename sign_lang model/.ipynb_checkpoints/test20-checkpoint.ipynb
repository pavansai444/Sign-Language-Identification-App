{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from matplotlib.rcsetup import validate_markevery\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = []\n",
    "label = []\n",
    "files = os.listdir(\"alphabets\")\n",
    "for i in tqdm(range(len(files))):\n",
    "      files_alpha = os.listdir(\"alphabets\"+\"/\"+files[i])\n",
    "      for j in  tqdm(range(len(files_alpha))):\n",
    "           sub_files_alpha = \"alphabets\"+\"/\"+files[i]+\"/\"+files_alpha[j] \n",
    "           image = cv2.imread(sub_files_alpha)\n",
    "           image = cv2.resize(image,(96,96))\n",
    "           image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "           img.append(image)\n",
    "           label.append(i)    #loading dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(img)\n",
    "label = np.array(label,dtype = \"int\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test =  train_test_split(img,label,test_size=0.20,shuffle=True)\n",
    "del img\n",
    "del label\n",
    "import gc\n",
    "gc.collect()     #split the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.applications import EfficientNetB0 \n",
    "from keras.models import Sequential,Model,load_model\n",
    "from keras import layers,optimizers,applications,utils\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "def get_Model():\n",
    "        k = EfficientNetB0(include_top = False,input_shape = (96,96,3))\n",
    "        model = Sequential()\n",
    "        model.add(k)          \n",
    "        model.add(layers.GlobalAveragePooling2D())\n",
    "        model.add(layers.Dropout(0.3))\n",
    "        model.add(Dense(25,activation = \"sigmoid\"))\n",
    "        model.summary()\n",
    "        return model         #create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, 25,dtype = \"int\")  #encoding for softmax\n",
    "y_test = to_categorical(y_test, 25,dtype = \"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_Model()\n",
    "model.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])  #compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"trained_model20/model\"    #create check point\n",
    "mcheck = ModelCheckpoint(filepath = path,monitor = \"val_accuracy\", mode = \"auto\",save_best_only =True,save_weights_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mreduceLR = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_accuracy\",\n",
    "    factor=0.9,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",           #reduce learning rate if the metric stopped improving\n",
    "    cooldown=0,\n",
    "    min_lr=0.00001,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit = model.fit(x_train,y_train,validation_data = (x_test,y_test),batch_size = 32,epochs =5,callbacks = [mcheck,mreduceLR])         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('new_model20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.applications import EfficientNetB0 \n",
    "from keras.models import Sequential,Model,load_model\n",
    "from keras import layers,optimizers,applications,utils\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "new_model = keras.models.load_model('new_model20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import numpy\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "imgwhite = 'A.jpg.jpg'\n",
    "list = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\"]\n",
    "image = cv2.imread(imgwhite)\n",
    "image = cv2.resize(image,(96,96))\n",
    "image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "image = image.reshape(-1,96,96,3)\n",
    "preds = new_model.predict(image)\n",
    "j = numpy.argmax(preds)\n",
    "print(list[j])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mediapipe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mctypes\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcvzone\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mHandTrackingModule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HandDetector\n\u001b[0;32m      8\u001b[0m cap  \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      9\u001b[0m detect \u001b[38;5;241m=\u001b[39m HandDetector(maxHands \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\cvzone\\HandTrackingModule.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mHand Tracking Module\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mBy: Computer Vision Zone\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mWebsite: https://www.computervision.zone/\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mHandDetector\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mediapipe'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import numpy\n",
    "import ctypes\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "cap  = cv2.VideoCapture(0)\n",
    "detect = HandDetector(maxHands = 1)\n",
    "ofs = 30\n",
    "imgsize = 500\n",
    "count = 0\n",
    "list = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\"]\n",
    "user32 = ctypes.windll.user32\n",
    "screen_width, screen_height = user32.GetSystemMetrics(0), user32.GetSystemMetrics(1)\n",
    "kar=True\n",
    "k = cv2.waitKey(1)\n",
    "s = ''\n",
    "while True:\n",
    "    time.sleep(0.1)\n",
    "    suc,img = cap.read()\n",
    "    frame_height, frame_width, _ = np.shape(img)\n",
    "    scaleWidth = float(screen_width)/float(frame_width)\n",
    "    scaleHeight = float(screen_height)/float(frame_height)\n",
    "\n",
    "    if scaleHeight>scaleWidth:\n",
    "       imgScale = scaleWidth\n",
    "\n",
    "    else:\n",
    "       imgScale = scaleHeight\n",
    "\n",
    "    newX,newY = frame_width*imgScale, frame_height*imgScale\n",
    "    img = cv2.resize(img,(int(newX),int(newY)))\n",
    "    \n",
    "    cv2.namedWindow(\"image\", cv2.WND_PROP_FULLSCREEN)\n",
    "    cv2.setWindowProperty(\"image\",cv2.WND_PROP_FULLSCREEN,cv2.WINDOW_FULLSCREEN)\n",
    "    \n",
    "    hand= detect.findHands(img,draw = False)\n",
    "    if hand:  \n",
    "       p = hand[0]\n",
    "       x,y,w,h = p[\"bbox\"]\n",
    "       imgwhite = np.ones((imgsize,imgsize,3),np.uint8)*255\n",
    "       imgcrop = img[y-ofs:y+h+ofs,x-ofs:x+w+ofs]\n",
    "       ratio = h/w\n",
    "      \n",
    "       if ratio>1:\n",
    "        k = imgsize/h\n",
    "        w = math.ceil(k*w)\n",
    "        imgresize = cv2.resize(imgcrop,(w,imgsize))\n",
    "        imgresizeshape = imgresize.shape\n",
    "        imgwhite[0:imgresizeshape[0], math.ceil((imgsize-imgresizeshape[1])/2):math.ceil((imgsize+imgresizeshape[1])/2) ] = imgresize\n",
    "\n",
    "        image = cv2.resize(imgwhite,(96,96))\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        image = image.reshape(-1,96,96,3)\n",
    "        preds = new_model.predict(image)\n",
    "        max = preds[0][0]\n",
    "        j = numpy.argmax(preds[0])\n",
    "        \n",
    "       else:\n",
    "        k = imgsize/w\n",
    "        h = math.ceil(k*h)\n",
    "        imgresize = cv2.resize(imgcrop,(imgsize,h))\n",
    "        imgresizeshape = imgresize.shape\n",
    "        imgwhite[ math.ceil((imgsize-h)/2):math.ceil((imgsize+h)/2),0:imgsize ] = imgresize\n",
    "        image = cv2.resize(imgwhite,(96,96))\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        image = image.reshape(-1,96,96,3)\n",
    "        preds = new_model.predict(image)\n",
    "        j = numpy.argmax(preds[0])\n",
    "    image = cv2.putText(img,list[j]+\"       \"+s,(90,90),cv2.FONT_HERSHEY_DUPLEX,3,(58,179,255),3)\n",
    "    cv2.imshow(\"image\",image)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k & 0xFF == ord('q'):     \n",
    "       s = s+'{}'.format(list[j])\n",
    "    if k & 0xFF ==ord('s'):\n",
    "       s = s[:-1]  \n",
    "    if k & 0xFF == ord('z'):\n",
    "       break\n",
    "      \n",
    "cap.release()\n",
    "print(s)      \n",
    "cv2.destroyAllWindows() \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cvzone\n",
      "  Downloading cvzone-1.5.6.tar.gz (12 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: opencv-python in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from cvzone) (4.6.0.66)\n",
      "Requirement already satisfied: numpy in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from cvzone) (1.21.5)\n",
      "Building wheels for collected packages: cvzone\n",
      "  Building wheel for cvzone (setup.py): started\n",
      "  Building wheel for cvzone (setup.py): finished with status 'done'\n",
      "  Created wheel for cvzone: filename=cvzone-1.5.6-py3-none-any.whl size=18750 sha256=db4f1b94bd08aa71aba6c08beb8d8ae96079a1c92c7a5aaf4e027eead86f1aff\n",
      "  Stored in directory: c:\\users\\pavan\\appdata\\local\\pip\\cache\\wheels\\6f\\ec\\e5\\c576c2f2fa138207498bbbfc8eefb1f0a2efbba7c847742948\n",
      "Successfully built cvzone\n",
      "Installing collected packages: cvzone\n",
      "Successfully installed cvzone-1.5.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cvzone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9c8f51c2bcd99038a123efae1ee7756ea171a50d229ddf75d24cb86cabf1426c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
