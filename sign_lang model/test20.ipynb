{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from matplotlib.rcsetup import validate_markevery\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = []\n",
    "label = []\n",
    "files = os.listdir(\"alphabets\")\n",
    "for i in tqdm(range(len(files))):\n",
    "      files_alpha = os.listdir(\"alphabets\"+\"/\"+files[i])\n",
    "      for j in  tqdm(range(len(files_alpha))):\n",
    "           sub_files_alpha = \"alphabets\"+\"/\"+files[i]+\"/\"+files_alpha[j] \n",
    "           image = cv2.imread(sub_files_alpha)\n",
    "           image = cv2.resize(image,(96,96))\n",
    "           image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "           img.append(image)\n",
    "           label.append(i)    #loading dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(img)\n",
    "label = np.array(label,dtype = \"int\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test =  train_test_split(img,label,test_size=0.20,shuffle=True)\n",
    "del img\n",
    "del label\n",
    "import gc\n",
    "gc.collect()     #split the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.applications import EfficientNetB0 \n",
    "from keras.models import Sequential,Model,load_model\n",
    "from keras import layers,optimizers,applications,utils\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "def get_Model():\n",
    "        k = EfficientNetB0(include_top = False,input_shape = (96,96,3))\n",
    "        model = Sequential()\n",
    "        model.add(k)          \n",
    "        model.add(layers.GlobalAveragePooling2D())\n",
    "        model.add(layers.Dropout(0.3))\n",
    "        model.add(Dense(25,activation = \"sigmoid\"))\n",
    "        model.summary()\n",
    "        return model         #create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, 25,dtype = \"int\")  #encoding for softmax\n",
    "y_test = to_categorical(y_test, 25,dtype = \"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_Model()\n",
    "model.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])  #compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"trained_model20/model\"    #create check point\n",
    "mcheck = ModelCheckpoint(filepath = path,monitor = \"val_accuracy\", mode = \"auto\",save_best_only =True,save_weights_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mreduceLR = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_accuracy\",\n",
    "    factor=0.9,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",           #reduce learning rate if the metric stopped improving\n",
    "    cooldown=0,\n",
    "    min_lr=0.00001,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit = model.fit(x_train,y_train,validation_data = (x_test,y_test),batch_size = 32,epochs =5,callbacks = [mcheck,mreduceLR])         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('new_model20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.applications import EfficientNetB0 \n",
    "from keras.models import Sequential,Model,load_model\n",
    "from keras import layers,optimizers,applications,utils\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "new_model = keras.models.load_model('new_model20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import numpy\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "imgwhite = 'A.jpg.jpg'\n",
    "list = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\"]\n",
    "image = cv2.imread(imgwhite)\n",
    "image = cv2.resize(image,(96,96))\n",
    "image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "image = image.reshape(-1,96,96,3)\n",
    "preds = new_model.predict(image)\n",
    "j = numpy.argmax(preds)\n",
    "print(list[j])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import numpy\n",
    "import ctypes\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "cap  = cv2.VideoCapture(0)\n",
    "detect = HandDetector(maxHands = 1)\n",
    "ofs = 30\n",
    "imgsize = 500\n",
    "count = 0\n",
    "list = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\"]\n",
    "user32 = ctypes.windll.user32\n",
    "screen_width, screen_height = user32.GetSystemMetrics(0), user32.GetSystemMetrics(1)\n",
    "kar=True\n",
    "k = cv2.waitKey(1)\n",
    "s = ''\n",
    "while True:\n",
    "    time.sleep(0.1)\n",
    "    suc,img = cap.read()\n",
    "    frame_height, frame_width, _ = np.shape(img)\n",
    "    scaleWidth = float(screen_width)/float(frame_width)\n",
    "    scaleHeight = float(screen_height)/float(frame_height)\n",
    "\n",
    "    if scaleHeight>scaleWidth:\n",
    "       imgScale = scaleWidth\n",
    "\n",
    "    else:\n",
    "       imgScale = scaleHeight\n",
    "\n",
    "    newX,newY = frame_width*imgScale, frame_height*imgScale\n",
    "    img = cv2.resize(img,(int(newX),int(newY)))\n",
    "    \n",
    "    cv2.namedWindow(\"image\", cv2.WND_PROP_FULLSCREEN)\n",
    "    cv2.setWindowProperty(\"image\",cv2.WND_PROP_FULLSCREEN,cv2.WINDOW_FULLSCREEN)\n",
    "    \n",
    "    hand= detect.findHands(img,draw = False)\n",
    "    if hand:  \n",
    "       p = hand[0]\n",
    "       x,y,w,h = p[\"bbox\"]\n",
    "       imgwhite = np.ones((imgsize,imgsize,3),np.uint8)*255\n",
    "       imgcrop = img[y-ofs:y+h+ofs,x-ofs:x+w+ofs]\n",
    "       ratio = h/w\n",
    "      \n",
    "       if ratio>1:\n",
    "        k = imgsize/h\n",
    "        w = math.ceil(k*w)\n",
    "        imgresize = cv2.resize(imgcrop,(w,imgsize))\n",
    "        imgresizeshape = imgresize.shape\n",
    "        imgwhite[0:imgresizeshape[0], math.ceil((imgsize-imgresizeshape[1])/2):math.ceil((imgsize+imgresizeshape[1])/2) ] = imgresize\n",
    "\n",
    "        image = cv2.resize(imgwhite,(96,96))\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        image = image.reshape(-1,96,96,3)\n",
    "        preds = new_model.predict(image)\n",
    "        max = preds[0][0]\n",
    "        j = numpy.argmax(preds[0])\n",
    "        \n",
    "       else:\n",
    "        k = imgsize/w\n",
    "        h = math.ceil(k*h)\n",
    "        imgresize = cv2.resize(imgcrop,(imgsize,h))\n",
    "        imgresizeshape = imgresize.shape\n",
    "        imgwhite[ math.ceil((imgsize-h)/2):math.ceil((imgsize+h)/2),0:imgsize ] = imgresize\n",
    "        image = cv2.resize(imgwhite,(96,96))\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        image = image.reshape(-1,96,96,3)\n",
    "        preds = new_model.predict(image)\n",
    "        j = numpy.argmax(preds[0])\n",
    "    image = cv2.putText(img,list[j]+\"       \"+s,(90,90),cv2.FONT_HERSHEY_DUPLEX,3,(58,179,255),3)\n",
    "    cv2.imshow(\"image\",image)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k & 0xFF == ord('q'):     \n",
    "       s = s+'{}'.format(list[j])\n",
    "    if k & 0xFF ==ord('s'):\n",
    "       s = s[:-1]  \n",
    "    if k & 0xFF == ord('z'):\n",
    "       break\n",
    "      \n",
    "cap.release()\n",
    "print(s)      \n",
    "cv2.destroyAllWindows() \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9c8f51c2bcd99038a123efae1ee7756ea171a50d229ddf75d24cb86cabf1426c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
